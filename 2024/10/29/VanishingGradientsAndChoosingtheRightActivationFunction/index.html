<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria | SPARKLE</title><meta name="keywords" content="python,Deep Learning"><meta name="author" content="sparkle520"><meta name="copyright" content="sparkle520"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria"><meta name="application-name" content="Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria"><meta property="og:url" content="http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/index.html"><meta property="og:site_name" content="SPARKLE"><meta property="og:description" content="author : Ayoosh Kathuria  Distributions, Damned Distributions and Statistics Neural networks, unlike the machine learning methods that came befo"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://pic.imgdb.cn/item/67179e86d29ded1a8c89ad6b.jpg"><meta property="article:author" content="sparkle520"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pic.imgdb.cn/item/67179e86d29ded1a8c89ad6b.jpg"><meta name="description" content="author : Ayoosh Kathuria  Distributions, Damned Distributions and Statistics Neural networks, unlike the machine learning methods that came befo"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: undefined,
  diytitle: {"enable":true,"leaveTitle":"w(ï¾ŸĞ”ï¾Ÿ)w ä¸è¦èµ°ï¼å†çœ‹çœ‹å˜›ï¼","backTitle":"â™ª(^âˆ‡^*)æ¬¢è¿è‚¥æ¥ï¼"},
  LA51: undefined,
  greetingBox: {"enable":true,"default":"æ™šä¸Šå¥½ğŸ‘‹","list":[{"greeting":"æ™šå®‰ğŸ˜´","startTime":0,"endTime":5},{"greeting":"æ—©ä¸Šå¥½é¸­ğŸ‘‹, ç¥ä½ ä¸€å¤©å¥½å¿ƒæƒ…ï¼","startTime":6,"endTime":9},{"greeting":"ä¸Šåˆå¥½ğŸ‘‹, çŠ¶æ€å¾ˆå¥½ï¼Œé¼“åŠ±ä¸€ä¸‹ï½","startTime":10,"endTime":10},{"greeting":"11ç‚¹å¤šå•¦, åœ¨åšæŒä¸€ä¸‹å°±åƒé¥­å•¦ï½","startTime":11,"endTime":11},{"greeting":"åˆå®‰ğŸ‘‹, å®è´","startTime":12,"endTime":14},{"greeting":"ğŸŒˆå……å®çš„ä¸€å¤©è¾›è‹¦å•¦ï¼","startTime":14,"endTime":18},{"greeting":"19ç‚¹å–½, å¥–åŠ±ä¸€é¡¿ä¸°ç››çš„å¤§é¤å§ğŸ”ã€‚","startTime":19,"endTime":19},{"greeting":"æ™šä¸Šå¥½ğŸ‘‹, åœ¨å±äºè‡ªå·±çš„æ—¶é—´å¥½å¥½æ”¾æ¾ğŸ˜Œ~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://sparkle521.xyz',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"","mailMd5":""},
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: false,
  mainTone: {"mode":"api","api":"https://img2color-go.vercel.app/api?img=","cover_change":true},
  authorStatus: {"skills":["(â¤ Ï‰ â¤)"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":330},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: 'å¤©',
  date_suffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"ä½œè€…: sparkle520","link":"é“¾æ¥: ","source":"æ¥æº: SPARKLE","info":"è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ã€‚å•†ä¸šè½¬è½½è¯·è”ç³»ä½œè€…è·å¾—æˆæƒï¼Œéå•†ä¸šè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ã€‚","copySuccess":"å¤åˆ¶æˆåŠŸï¼Œå¤åˆ¶å’Œè½¬è½½è¯·æ ‡æ³¨æœ¬æ–‡åœ°å€"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"ä½ å·²åˆ‡æ¢ä¸ºç¹ä½“","cht_to_chs":"ä½ å·²åˆ‡æ¢ä¸ºç®€ä½“","day_to_night":"ä½ å·²åˆ‡æ¢ä¸ºæ·±è‰²æ¨¡å¼","night_to_day":"ä½ å·²åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼","bgLight":"#883ced","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'SPARKLE',
  title: 'Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria',
  postAI: '',
  pageFillDescription: 'Vanishing Gradients, Saturated Neurons, ReLU to the rescue, One-sided Saturations, Sparsity, The Dying ReLU Problem, Zero-centered activations, Revisting Saturation, Conclusion',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-12-25 11:09:35',
  postMainColor: '#01143f',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-dark.min.css"><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="åŠ è½½å¤´åƒ" src="https://pic.imgdb.cn/item/65b6b29c871b83018af70c9a.png"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">ç½‘é¡µ</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/sparkle520?tab=repositories" title="github"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="github"/><span class="back-menu-item-text">github</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">SPARKLE</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æ–‡ç« </span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> åˆ†ç±»</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> å‹é“¾</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> å‹äººå¸</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æˆ‘çš„</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> ç›¸å†Œé›†</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> å°ç©ºè°ƒ</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> å…³äº</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> é—²è¨€ç¢è¯­</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> éšä¾¿é€›é€›</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="éšæœºå‰å¾€ä¸€ä¸ªæ–‡ç« " href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="æœç´¢ğŸ”" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> æœç´¢</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="ä¸­æ§å°" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="å¾®ä¿¡" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">å¾®ä¿¡</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="æ”¯ä»˜å®" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">æ”¯ä»˜å®</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">äº’åŠ¨</div><span class="author-content-item-title"> æœ€æ–°è¯„è®º</span></div><div class="aside-list"><span>æ­£åœ¨åŠ è½½ä¸­...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">å…´è¶£ç‚¹</div><span class="author-content-item-title">å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„é¢†åŸŸ</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/408/" style="font-size: 1.05rem;">408<sup>10</sup></a><a href="/tags/AOP/" style="font-size: 1.05rem;">AOP<sup>1</sup></a><a href="/tags/Deep-Learning/" style="font-size: 1.05rem;">Deep Learning<sup>1</sup></a><a href="/tags/IoC/" style="font-size: 1.05rem;">IoC<sup>1</sup></a><a href="/tags/JSR303/" style="font-size: 1.05rem;">JSR303<sup>1</sup></a><a href="/tags/Matplotlib/" style="font-size: 1.05rem;">Matplotlib<sup>3</sup></a><a href="/tags/c/" style="font-size: 1.05rem;">c#<sup>2</sup></a><a href="/tags/java/" style="font-size: 1.05rem;">java<sup>4</sup></a><a href="/tags/npc%E5%88%86%E6%9E%90%E6%B3%95/" style="font-size: 1.05rem;">npcåˆ†ææ³•<sup>1</sup></a><a href="/tags/python/" style="font-size: 1.05rem;">python<sup>5</sup></a><a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 1.05rem;">äº‹åŠ¡<sup>1</sup></a><a href="/tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B/" style="font-size: 1.05rem;">äºŒæ¬¡å‹<sup>1</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E3%80%82/" style="font-size: 1.05rem;">ä½ çš„åå­—ã€‚<sup>3</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E5%90%8C%E5%90%8D%E5%B0%8F%E8%AF%B4/" style="font-size: 1.05rem;">ä½ çš„åå­—åŒåå°è¯´<sup>1</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E5%A4%96%E4%BC%A0%E5%B0%8F%E8%AF%B4/" style="font-size: 1.05rem;">ä½ çš„åå­—å¤–ä¼ å°è¯´<sup>1</sup></a><a href="/tags/%E5%80%92%E8%A3%85%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">å€’è£…ç»“æ„<sup>1</sup></a><a href="/tags/%E5%86%99%E4%BD%9C/" style="font-size: 1.05rem;">å†™ä½œ<sup>4</sup></a><a href="/tags/%E5%8C%85%E7%AE%A1%E7%90%86/" style="font-size: 1.05rem;">åŒ…ç®¡ç†<sup>1</sup></a><a href="/tags/%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F/" style="font-size: 1.05rem;">å·ç§¯å…¬å¼<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90/" style="font-size: 1.05rem;">å¤©æ°”ä¹‹å­<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90%E5%90%8C%E5%90%8D%E5%B0%8F%E8%AF%B4/" style="font-size: 1.05rem;">å¤©æ°”ä¹‹å­åŒåå°è¯´<sup>1</sup></a><a href="/tags/%E5%AE%9A%E7%A7%AF%E5%88%86/" style="font-size: 1.05rem;">å®šç§¯åˆ†<sup>1</sup></a><a href="/tags/%E5%B0%8F%E8%AF%B4/" style="font-size: 1.05rem;">å°è¯´<sup>3</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">æ“ä½œç³»ç»Ÿ<sup>5</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/" style="font-size: 1.05rem;">æ•°æ®æ ¡éªŒ<sup>1</sup></a><a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 1.05rem;">æ¦‚ç‡è®º<sup>1</sup></a><a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/" style="font-size: 1.05rem;">æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡<sup>7</sup></a><a href="/tags/%E6%B1%87%E7%BC%96/" style="font-size: 1.05rem;">æ±‡ç¼–<sup>9</sup></a><a href="/tags/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80/" style="font-size: 1.05rem;">æ³°å‹’å±•å¼€<sup>1</sup></a><a href="/tags/%E7%89%B9%E5%BE%81%E5%80%BC/" style="font-size: 1.05rem;">ç‰¹å¾å€¼<sup>1</sup></a><a href="/tags/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/" style="font-size: 1.05rem;">ç‰¹å¾å‘é‡<sup>1</sup></a><a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 1.05rem;">çº¿æ€§ä»£æ•°<sup>1</sup></a><a href="/tags/%E8%8B%B1%E8%AF%AD%E5%90%AC%E5%8A%9B/" style="font-size: 1.05rem;">è‹±è¯­å¬åŠ›<sup>1</sup></a><a href="/tags/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/" style="font-size: 1.05rem;">è‹±è¯­è¯­æ³•<sup>16</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" style="font-size: 1.05rem;">è®¡ç®—æœºç»„æˆåŸç†<sup>6</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 1.05rem;">è®¡ç®—æœºç½‘ç»œ<sup>1</sup></a><a href="/tags/%E8%AF%8D%E6%A0%B9%E8%AF%8D%E7%BC%80/" style="font-size: 1.05rem;">è¯æ ¹è¯ç¼€<sup>1</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/" style="font-size: 1.05rem;">é«˜ç­‰ä»£æ•°<sup>2</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/" style="font-size: 1.05rem;">é«˜ç­‰æ•°å­¦<sup>9</sup></a><a href="/tags/%E9%AB%98%E9%A2%91%E8%AF%8D%E7%BB%84/" style="font-size: 1.05rem;">é«˜é¢‘è¯ç»„<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>æ–‡ç« </span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>å½’æ¡£</span><a class="card-more-btn" href="/archives/" title="æŸ¥çœ‹æ›´å¤š">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2026/02/"><span class="card-archive-list-date">äºŒæœˆ 2026</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2026/01/"><span class="card-archive-list-date">ä¸€æœˆ 2026</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/12/"><span class="card-archive-list-date">åäºŒæœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">15</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/11/"><span class="card-archive-list-date">åä¸€æœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/10/"><span class="card-archive-list-date">åæœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">ä¹æœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">å…«æœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>ç¯‡</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">ä¸ƒæœˆ 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>ç¯‡</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="æ˜¾ç¤ºæ¨¡å¼åˆ‡æ¢" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="è¾¹æ æ˜¾ç¤ºæ§åˆ¶"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="çƒ­è¯„å¼€å…³"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="åˆ‡æ¢"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">åŸåˆ›</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url">è®¡ç®—æœº</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/python/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>python</span></a><a class="article-meta__tags" href="/tags/Deep-Learning/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Deep Learning</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-10-29T14:00:27.000Z" title="å‘è¡¨äº 2024-10-29 22:00:27">2024-10-29</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-12-25T03:09:35.352Z" title="æ›´æ–°äº 2025-12-25 11:09:35">2025-12-25</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="æ–‡ç« å­—æ•°"></i><span class="post-meta-label" title="æ–‡ç« å­—æ•°">å­—æ•°æ€»è®¡:</span><span class="word-count" title="æ–‡ç« å­—æ•°">3.7k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="é˜…è¯»æ—¶é•¿"></i><span class="post-meta-label" title="é˜…è¯»æ—¶é•¿">é˜…è¯»æ—¶é•¿:</span><span>22åˆ†é’Ÿ</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="é˜…è¯»é‡">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="ä½œè€…IPå±åœ°ä¸ºç³»å®ˆé•‡"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>ç³»å®ˆé•‡</span><span class="post-meta-separator"></span><span class="post-meta-commentcount"><i class="anzhiyufont anzhiyu-icon-comments post-meta-icon"></i><span class="post-meta-label">è¯„è®ºæ•°:</span><a href="/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/#post-comment" tabindex="-1"><span id="twikoo-count"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://pic.imgdb.cn/item/67179e86d29ded1a8c89ad6b.jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/"><header><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url">è®¡ç®—æœº</a><a href="/tags/python/" tabindex="-1" itemprop="url">python</a><a href="/tags/Deep-Learning/" tabindex="-1" itemprop="url">Deep Learning</a><h1 id="CrawlerTitle" itemprop="name headline">Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">sparkle520</span><time itemprop="dateCreated datePublished" datetime="2024-10-29T14:00:27.000Z" title="å‘è¡¨äº 2024-10-29 22:00:27">2024-10-29</time><time itemprop="dateCreated datePublished" datetime="2025-12-25T03:09:35.352Z" title="æ›´æ–°äº 2025-12-25 11:09:35">2025-12-25</time></header><blockquote>
<p><strong>author</strong> : <strong>Ayoosh Kathuria</strong></p>
</blockquote>
<h1
id="distributions-damned-distributions-and-statistics">Distributions,
Damned Distributions and Statistics</h1>
<p>Neural networks, unlike the machine learning methods that came before
them, do not rest upon any probabilistic or statistical assumptions
about the data they are fed. However, one of the most, if not the most
important element required to ensure that neural networks learn properly
is that the data fed to the layers of a neural network exhibit certain
properties.</p>
<div style="margin:0 32px">
1.The data distribution should be zero centered, i.e the mean of the
distribution should be around zero. Absence of this can cause vanishing
gradients and jittery training.
</div>
<div style="margin:0 32px">
2.It is preferred that the distribution be a normal one. Absence of this
can cause the network to overfit to a domain of input space.
</div>
<div style="margin:0 32px">
3.The distributions of the activations, both across the batch as well as
the across a layer, should remain somewhat constant as the training goes
by. Absence of this is called Internal Covariate shift, and this may
slow down training.
</div>
<div style="margin-top:32px">

</div>
<p>In this article, we will cover problems No.Â <span
class="math inline">\(1\)</span> and <span
class="math inline">\(2\)</span>, and how activation functions are used
to address them. We end with some practical advice to choose which
activation function to chose for your deep network.</p>
<h1 id="vanishing-gradients">Vanishing Gradients</h1>
<p>The problem of vanishing gradients is well documented, and gets much
more pronounced as we go deeper and deeper with neural networks. Let us
understand why they happen. Imagine the possibly simplest neural
network. A bunch of neurons stacked linearly.</p>
<p>One can easily extend this analogy to deeper densely connected
architectures. In fact, one can easily do that by replacing each neuron
in the network by a full layer. Each of the neurons use a Sigmoid
non-linearity as itâ€™s activation function.</p>
<p><img
src="https://pic.imgdb.cn/item/6720eeb6d29ded1a8c6805ee.png" /></p>
<p>The graph for a sigmoid function looks like this.</p>
<p><img
src="https://pic.imgdb.cn/item/6720f9bdd29ded1a8c71453a.png" /></p>
<details class="folding-tag" ><summary> show draw code </summary>
              <div class='content'>
              <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">y1 = sigmoid(x)</span><br><span class="line">y2 = np.ones(<span class="number">100</span>)</span><br><span class="line">y3 = np.ones(<span class="number">100</span>) / <span class="number">2</span></span><br><span class="line">y4 = np.zeros(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">ax.plot(x, y1, color=<span class="string">&#x27;#ff9999&#x27;</span>, label=<span class="string">r&#x27;$\phi(z)=\frac&#123;1&#125;&#123;1+e^&#123;-z&#125;&#125;$&#x27;</span>)</span><br><span class="line">ax.plot(x, y2, color=<span class="string">&#x27;#8674a1&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ax.plot(x, y3, color=<span class="string">&#x27;#8674a1&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ax.plot(x, y4, color=<span class="string">&#x27;#8674a1&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="string">&#x27;best&#x27;</span>, frameon=<span class="literal">False</span>, prop=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">15</span>&#125;)</span><br><span class="line"></span><br><span class="line">x_ticks = np.arange(-<span class="number">10</span>, <span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">y_ticks = np.arange(<span class="number">0</span>, <span class="number">2</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.xticks(x_ticks)</span><br><span class="line">plt.yticks(y_ticks)</span><br><span class="line">plt.xlim(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">plt.ylim(-<span class="number">0.2</span>, <span class="number">1.2</span>)</span><br><span class="line">plt.tick_params(direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, -<span class="number">0.2</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_position((<span class="string">&#x27;axes&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Sigmoid&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
              </div>
            </details>
<p>If you look at the slope of the sigmoid function, you will realize it
tends to zero on either of the fringes. Or better, let us look at the
plot of the gradient of the sigmoid function.</p>
<p><img
src="https://pic.imgdb.cn/item/6720ff84d29ded1a8c763419.png" /></p>
<details class="folding-tag" ><summary> show draw code </summary>
              <div class='content'>
              <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_derivative</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / (np.exp(<span class="number">2</span>*x) + <span class="number">2</span> * np.exp(x)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">y1 = sigmoid(x)</span><br><span class="line">y2 = sigmoid_derivative(x)</span><br><span class="line">y3 = np.ones(<span class="number">100</span>)</span><br><span class="line">y4 = np.zeros(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">ax.plot(x, y1, color=<span class="string">&#x27;#ff9999&#x27;</span>, label=<span class="string">&#x27;Sigmoid s(z)&#x27;</span>)</span><br><span class="line">ax.plot(x, y2, color=<span class="string">&#x27;#aa96da&#x27;</span>, label=<span class="string">&quot;Derivative s&#x27;(z)&quot;</span>)</span><br><span class="line">ax.plot(x, y3, color=<span class="string">&#x27;#8674a1&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ax.plot(x, y4, color=<span class="string">&#x27;#8674a1&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="string">&#x27;best&#x27;</span>, frameon=<span class="literal">False</span>, prop=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">8</span>&#125;)</span><br><span class="line"></span><br><span class="line">x_ticks = np.arange(-<span class="number">10</span>, <span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">y_ticks = np.arange(<span class="number">0</span>, <span class="number">2</span>, <span class="number">0.5</span>)</span><br><span class="line">plt.xticks(x_ticks)</span><br><span class="line">plt.yticks(y_ticks)</span><br><span class="line">plt.xlim(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">plt.ylim(-<span class="number">0.2</span>, <span class="number">1.2</span>)</span><br><span class="line">plt.tick_params(direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, -<span class="number">0.2</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_position((<span class="string">&#x27;axes&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Sigmoid&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
              </div>
            </details>
<p>When we differentiate the output of a sigmoid activation layer with
respect to itâ€™s weights , we see that the gradient of the sigmoid
function is a factor in the expression. This gradient has a value
ranging from <span class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>.</p>
<p><span
class="math display">\[\frac{\partial(\sigma(\omega^Tx+b))}{\partial\omega}=\frac{\partial(\sigma(\omega^Tx+b))}{\partial(\omega^Tx+b)}*\frac{\partial(\omega^Tx+b)}{\partial\omega}\]</span></p>
<p>The second term is a sigmoid derivative, which has a range of <span
class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>.</p>
<p>Going back to our example, let us figure out the gradient rule for
neuron A. Applying chain rule, we see that the gradient for neuron A
looks like</p>
<p><span class="math display">\[\frac{\partial L}{\partial
a}=\frac{\partial L}{\partial d}*\frac{\partial d}{\partial
c}*\frac{\partial c}{\partial b}*\frac{\partial b}{\partial
a}\]</span></p>
<p>Realize, that each of the term in the expression above can be further
factorized to a product of gradients, one of which is a gradient of the
sigmoid function. For instance,</p>
<p><span class="math display">\[\frac{\partial d}{\partial
c}=\frac{\partial
d}{\partial(\sigma(\omega_d^Tc+b_d))}*\frac{\partial(\sigma(\omega_d^Tc+b_d))}{\partial(\omega_d^Tc+b_d)}*\frac{\partial(\omega_d^Tc+b_d)}{\partial
c}\]</span></p>
<p>Now, let us suppose instead of <span class="math inline">\(3\)</span>
neurons in front of A, there are about <span
class="math inline">\(50\)</span> neurons in front of A. This is totally
plausible in a practical scenario where networks may easily have <span
class="math inline">\(50\)</span> layers.</p>
<p>Then the gradient expression of A has a product of 50 sigmoid
gradients in it, and as each such term has a value between <span
class="math inline">\(0\)</span> and <span
class="math inline">\(1\)</span>, the value of the gradient of A might
be driven to zero.</p>
<p>To see how this might happen, letâ€™s do a simple experiment. Let us
randomly sample <span class="math inline">\(50\)</span> numbers from
<span class="math inline">\(0\)</span> to <span
class="math inline">\(1\)</span>, and then multiply them altogether.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line">li = [random.uniform(<span class="number">0</span>,<span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>)</span><br><span class="line"><span class="built_in">print</span>(reduce(<span class="keyword">lambda</span> x,y: x*y, li))</span><br></pre></td></tr></table></figure>
<p>Go try it yourself. Despite repeated attempts, I could never get a
value of order more than <span class="math inline">\(10^{-18}\)</span>.
If this value is present in the gradient expression of neuron A as a
factor, then itâ€™s gradient would be almost negligible. This means, in
deeper architectures, no learning happens for the deeper neurons, or if
it happens, it does so at a remarkably slower rate than the learning for
the shallower higher layers.</p>
<p>Such a phenomenon is called the Vanishing Gradients Problem, wherein
the gradients of the deeper neurons become zero or to say, vanish . The
problem then is that the deeper layers of the network learn very slowly,
or in worst case, the deeper layers donâ€™t learn at all.</p>
<h1 id="saturated-neurons">Saturated Neurons</h1>
<p>The problems of Vanishing gradients can be worsened by saturated
neurons. Suppose, that pre-activation <span
class="math inline">\(\omega^Tx+b\)</span> that is fed to a neuron with
a Sigmoid activation is either very high or very low. The gradient of
sigmoid at very high or low values is almost <span
class="math inline">\(0\)</span>. Any gradient update would hardly
produce a change in the weights <span
class="math inline">\(\omega\)</span> and the bias <span
class="math inline">\(b\)</span>, and it would take a lot of steps for
the neuron to get modify weights so that the pre-activation falls in an
area where the gradient has a substantial value.</p>
<h1 id="relu-to-the-rescue">ReLU to the rescue</h1>
<p>The first attempt at curbing the problem of vanishing gradients in a
general deep network setting (LSTMs were introduced to combat this as
well, but they were restricted to recurrent models) was the introduction
of the ReLU activation function.</p>
<p><img
src="https://pic.imgdb.cn/item/67211360d29ded1a8c86caef.png" /></p>
<details class="folding-tag" ><summary> show draw code </summary>
              <div class='content'>
              <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relu</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">7</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw sigmoid</span></span><br><span class="line">axes1 = fig.add_axes([<span class="number">0.06</span>, <span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.8</span>])  <span class="comment"># [left, bottom, width, height]</span></span><br><span class="line"></span><br><span class="line">y1 = sigmoid(x)</span><br><span class="line">x1_ticks = np.arange(-<span class="number">10</span>, <span class="number">11</span>, <span class="number">5</span>)</span><br><span class="line">y1_ticks = np.arange(<span class="number">0</span>, <span class="number">1.2</span>, <span class="number">0.2</span>)</span><br><span class="line">axes1.tick_params(direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">axes1.plot(x, y1, color=<span class="string">&#x27;#ff9999&#x27;</span>, linewidth=<span class="number">3</span>, label=<span class="string">r&#x27;$\sigma(z)=\frac&#123;1&#125;&#123;1+e^&#123;-z&#125;&#125;$&#x27;</span>)</span><br><span class="line">axes1.legend(loc=<span class="string">&#x27;best&#x27;</span>, frameon=<span class="literal">False</span>, prop=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">12</span>&#125;)</span><br><span class="line">axes1.set_xticks(x1_ticks)</span><br><span class="line">axes1.set_yticks(y1_ticks)</span><br><span class="line">axes1.set_xlim(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">axes1.set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">axes1.set_title(<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">axes1.grid(alpha=<span class="number">0.4</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw ReLU</span></span><br><span class="line">axes2 = fig.add_axes([<span class="number">0.56</span>, <span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.8</span>])</span><br><span class="line"></span><br><span class="line">y2 = relu(x)</span><br><span class="line">x2_ticks = np.arange(-<span class="number">10</span>, <span class="number">12</span>, <span class="number">5</span>)</span><br><span class="line">y2_ticks = np.arange(<span class="number">0</span>, <span class="number">12</span>, <span class="number">2</span>)</span><br><span class="line">axes2.plot(x, y2, color=<span class="string">&#x27;#00b8a9&#x27;</span>, linewidth=<span class="number">3</span>, label=<span class="string">r&#x27;$R(z)=max(0, z)$&#x27;</span>)</span><br><span class="line">axes2.legend(loc=<span class="string">&#x27;best&#x27;</span>, frameon=<span class="literal">False</span>, prop=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">12</span>&#125;)</span><br><span class="line">axes2.set_xticks(x2_ticks)</span><br><span class="line">axes2.set_yticks(y2_ticks)</span><br><span class="line">axes2.set_xlim(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">axes2.set_ylim(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line">axes2.set_title(<span class="string">&#x27;ReLU&#x27;</span>)</span><br><span class="line">axes2.grid(alpha=<span class="number">0.4</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tick_params(direction=<span class="string">&#x27;in&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
              </div>
            </details>
<p>The gradient of ReLU is <span class="math inline">\(1\)</span> for
<span class="math inline">\(x&gt;0\)</span> and <span
class="math inline">\(0\)</span> for <span
class="math inline">\(x&lt;0\)</span>. It has multiple benefits. The
product of gradients of ReLU function doesnâ€™t end up converging to <span
class="math inline">\(0\)</span> as the value is either <span
class="math inline">\(0\)</span> or <span
class="math inline">\(1\)</span>. If the value is <span
class="math inline">\(1\)</span>, the gradient is back propagated as it
is. If it is <span class="math inline">\(0\)</span>, then no gradient is
backpropagated from that point backwards.</p>
<h1 id="one-sided-saturations">One-sided Saturations</h1>
<p>We had a two-sided saturation in the sigmoid functions. That is the
activation function would saturate in both the positive and the negative
direction. In contrast, ReLUs provide one-sided saturations.</p>
<p>Though it is not exactly precise to call the zero part of a ReLU a
saturation. However, it serves the same purpose in a way that the value
of the function doesnâ€™t vary at all (as opposed to very very small
variation in proper saturation) as the input to the function becomes
more and more negative. What benefit might a one-sided saturation bring
you may ask?</p>
<p>Weâ€™d like to think neurons in a deep network like switches, which
specialize in detecting certain features, which are often termed as
concepts. While the neurons in the higher layers might end up
specializing in detecting high level concepts like eyes, tyres etc, the
neurons in lower layers end up specializing in low-level concepts such
as curves, edges etc.</p>
<p>We want the neurons to fire when such a concept in present in the
input it gets, and the magnitude of it is a measure of the extent of the
concept in the input. For example, if a neuron detects an edge, itâ€™s
magnitude might represent the sharpness of an edge.</p>
<p><img
src="https://pic.imgdb.cn/item/672114efd29ded1a8c881c7f.png" /></p>
<center>
Activation maps created by neurons learn different concepts
</center>
<p>However, it doesnâ€™t make sense as to have an unbounded negative value
for a neuron. While itâ€™s intuitive to interpret the confidence in
presence of a concept, itâ€™s quite odd to to encode the absence of a
concept.</p>
<p>Considering the example related to a neuron detecting edges, having
an activation of <span class="math inline">\(10\)</span> as compared as
to an activation of <span class="math inline">\(5\)</span> might mean a
more sharper edge. But what sense does a value of -<span
class="math inline">\(10\)</span> make when compared to -<span
class="math inline">\(5\)</span>, wherein below a value below zero
represents no edge at all. Therefore, itâ€™d be convenient to have a
uniform value of zero for all the input that corresponds to the case of
the concept being absent ( some other concept might be present or none
at all ). ReLUs with their one-sided saturation accomplish exactly
that.</p>
<h1 id="information-disentanglement-and-robustness-to-noise">Information
Disentanglement and Robustness to Noise</h1>
<p>Having one-sided saturation makes a neuron robust to noise. Why? Let
us assume that we have a neurons values of which are unbounded,
i.e.Â donâ€™t saturate in either of the direction. The inputs which contain
the concept to varying degrees produce variance in the positive output
of the neuron. This is fine as we want the magnitude to be a indicator
of the strength of the signal.</p>
<p>However, the variance in the signal bought about background noise, or
concepts the neuron doesnâ€™t specialize in ( region containing arcs being
fed to neurons that specialize in detecting lines ) produce variance in
the the negative output of the neuron .This type of variance can
contribute extraneous useless information to other neurons which have
dependencies with the particular neuron we are talking about. This can
also lead to correlated units. For example, a neuron that detects lines
might have a negative correlation with a neuron that detects arcs.</p>
<p>Now, let us consider the same scenario with a neuron that saturates
in the negative region, ( for preactivation <span
class="math inline">\(&lt; 0\)</span> ). Here, the variance due to
noise, which showed up as negative magnitude earlier is squashed by the
saturating element of the activation function. This prevents noise from
producing extraneous signals.</p>
<h1 id="sparsity">Sparsity</h1>
<p>Using a ReLu activation function also has computational benefits.
ReLU based networks train quicker since no significant computation is
spent in calculating the gradient of a ReLU activation. This is contrast
to Sigmoid where exponentials would need to be computed in order to
calculate gradients.</p>
<p>Since ReLUâ€™s clamp the negative preactivations to zero, they
implicitly introduce sparsity in the network, which can be exploited for
computational benefits.</p>
<h1 id="the-dying-relu-problem">The Dying ReLU Problem</h1>
<p>ReLUs come with their own set of shortcomings. While sparsity is a
computational advantage, too much of it can actually hamper learning.
Normally, the pre-activation also contains a bias term. If this bias
term becomes too negative such that <span
class="math inline">\(\omega^Tx+b&lt;0\)</span>, then the gradient of
the ReLU activation during backward pass is 0. <strong>Therefore, the
weights and the bias causing the negative preactivations cannot be
updated.</strong></p>
<p>If the weights and bias learned is such that the preactivation is
negative for the entire domain of inputs, the neuron never learns,
causing a sigmoid-like saturation. This is known as the dying ReLU
problem.</p>
<h1 id="zero-centered-activations">Zero-centered activations</h1>
<p>Since ReLUs only output non-negative activations regardless of itâ€™s
input, they will always produce positive activations. This can be a
drawback. Let us understand how.</p>
<p>For a ReLU based neural network, the gradient for any set of weights
<span class="math inline">\(\omega_{n}\)</span> belonging to a layer
<span class="math inline">\(l_{n}\)</span> having an activation <span
class="math inline">\(z_n=ReLU(\omega_n^Tx_n+b_n)\)</span> for the loss
function <span class="math inline">\(L\)</span></p>
<p><span class="math display">\[\frac{\partial
L}{\partial\omega_n}=\frac{\partial
L}{\partial(ReLU(\omega_n^Tx_n+b_n))}*I(ReLU(\omega_n^Tx_n+b_n))*x_n\]</span></p>
<p>Here,<span
class="math inline">\(I(ReLU(\omega_n^Tx_n+b_n)&gt;0)\)</span> is a
indicator function which is 1 when the condition passed as itâ€™s
arguement is true, and 0 otherwise. Since, a ReLU only outputs a
non-negative value( <span class="math inline">\(x_n\)</span> ).Since
each element of <span class="math inline">\(x_n\)</span> is either
positive or zero, the gradient update for each weight in <span
class="math inline">\(\omega_{n}\)</span> has the same sign as <span
class="math inline">\(\frac{\partial
L}{\partial(ReLU(\omega_n^Tx_n+b_n))}\)</span></p>
<p>Now how is that a problem? The problem is that since the sign of
gradient update for all neurons is the same, all the weights of the
layer <span class="math inline">\(l_n\)</span> can either increase or
decrease during one update. However, the ideal gradient weight update
might be one where some weights increase while the other weights
decrease. This is not possible with ReLU.</p>
<p>Suppose some weights need to decrease in accordance to an ideal
weight update. However, if the gradient update is positive, these
weights become too positive in the current iteration. In the next
iteration, the gradient may be negative as well as large to remedy these
increased weights, which might end up overshooting the weights which
need little negative change or a positive change.</p>
<p>This can cause a zig zag patter in search of minima, which can slow
down the training.</p>
<div class="img-wrap"><div class="img-bg"><img class="img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/67211717d29ded1a8c89b45a.png" style="width:600px;"/></div></div>
<center>
Problem with Leaky ReLUs
</center>
<h1 id="leaky-relus-and-parameterized-relus">Leaky ReLUs and
Parameterized ReLUs</h1>
<p>In order to combat the problem of dying ReLUs, the leaky ReLU was
proposed. A Leaky ReLU is same as normal ReLU, except that instead of
being 0 for <span class="math inline">\(x&lt;0\)</span>, it has a small
negative slope for that region.</p>
<div class="img-wrap"><div class="img-bg"><img class="img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/6721175bd29ded1a8c89e757.png" style="width:600px;"/></div></div>
<p>In practice, the negative slope, <span
class="math inline">\(\alpha\)</span> is chosen to be a value of the
order <span class="math inline">\(0.01\)</span>.</p>
<p>The benefit with Leaky ReLUâ€™s is that the backward pass is able to
alter weights which produce a negative preactivation as the gradient of
the activation function for inputs <span
class="math inline">\(x&lt;0\)</span> is <span
class="math inline">\(\alpha e^x\)</span>. For example Leaky ReLU is
used in YOLO object detection algorithm.</p>
<p>Since, the negative pre-activations produce negative values instead
of <span class="math inline">\(0\)</span>, we do not have the problem
regarding weights being updated only in one direction that was
associated with ReLU.</p>
<p>The value of <span class="math inline">\(\alpha\)</span> is something
people have experimented quite a bit with. There exists an approach
which is called Randomized Leaky ReLU, where the negative slope is
randomly chosen from a uniform distribution with mean <span
class="math inline">\(0\)</span> and standard deviation <span
class="math inline">\(1\)</span>.</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
x, &amp; x&gt;0 \\\\
\alpha x, &amp; x\le 0
\end{cases}
,\quad \alpha \sim U(0,1)
\]</span></p>
<p>The original paper of Randomized ReLU claims that it produces better
and faster results than leaky ReLU and proposes, through empirical
means, that if we were limited to only a single choice of <span
class="math inline">\(\alpha\)</span>, as in Leaky ReLU, a choice of
<span class="math inline">\(\frac{1}{5.5}\)</span>would work better than
<span class="math inline">\(0.01\)</span></p>
<p>The reason why Randomized Leaky ReLU works is due to the random
choice of negative slope, hence randomness of gradients for negative
preactivations, which introduces randomness in the optimization
algorithm. This randomness, or noise helps us steer clear of local
minima and saddle points. If you need more perspective on this, I
encourage you to checkout the first part of the series where we have
talked in depth about the topic.</p>
<p>Taking the benefit of a different negative slope for each neuron,
people have taken the approach further by not randomly sampling the
negative slope <span class="math inline">\(\alpha\)</span> but turning
it into a hyperparameter, which is learned by the network during
training. Such an activation is called Parametrized ReLU.</p>
<h1 id="revisting-saturation">Revisting Saturation</h1>
<p>While neuron saturation seems like a very bad thing to have in a
neural network, having one sided saturation, like we had in ReLU isnâ€™t
necessarily that bad. While the above discussed variants of ReLU
contribute to zero-centered activations, they donâ€™t have the benefits of
one-sided saturation as discussed above.</p>
<h1 id="exponential-linear-units-and-bias-shift">Exponential Linear
Units and Bias Shift</h1>
<p>Following the discussion above it seems as if the perfect activation
function has two desirable properties:</p>
<p>â€ƒ1.Producing a zero-centered distribution, which can make the
training faster. â€ƒ2.Having one-sided saturation which leads to better
convergence.</p>
<p>While Leaky ReLUs and PReLU solve the first condition, they fall
short on the second one. On the other hand, a vanilla ReLU satisfies the
second but not the first condition.</p>
<p>An activation function that satisfies both the conditions is an
Exponential Linear Unit (ELU).</p>
<div class="img-wrap"><div class="img-bg"><img class="img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/6721189cd29ded1a8c8abb93.png" style="width:600px;"/></div></div>
<p><span
class="math display">\[f(x)=\left\{\begin{array}{ll}x&amp;when&amp;x&gt;0\\[.5em]\alpha(e^x-1)&amp;when&amp;x\leq0\end{array}\right.\]</span></p>
<p>The gradient of the function is <span
class="math inline">\(1\)</span> for <span
class="math inline">\(x&gt;0\)</span>while it is <span
class="math inline">\(\alpha*e^{x}\)</span> for <span
class="math inline">\(x&lt;0\)</span>. The function saturates for
negative values to <span class="math inline">\(\alpha\)</span> value of
<span class="math inline">\(-\alpha\)</span>. <span
class="math inline">\(\alpha\)</span> is a hyperparameter that is
normally chosen to be <span class="math inline">\(1\)</span>.</p>
<p>Since, the function does have a region of negative values, we no
longer have the problem of non-zero centered activations causing erratic
training.</p>
<h1 id="how-to-chose-a-activation-function">How to chose a activation
function</h1>
<p>â€ƒ1.Try your luck with a ReLU activation. Despite the fact we have
outlined problems with ReLU, a lot of people have achieved good results
with ReLU. In accordance with the principal of Occamâ€™s Razor, itâ€™s
better to try out simpler stuff first. ReLUs, among all the other viable
contenders have the cheapest computational budget, as well are dead
simple to implement if your project requires coding up from scratch.</p>
<p>â€ƒ2.If ReLU doesnâ€™t output promising results, my next choice is a
either a Leaky ReLU or a ELU. Iâ€™ve found that activations which are
capable of producing zero centered activations are much better than the
ones which donâ€™t. ELU might have been a a very easy choice, but ELU
based networks are slow to train as well slow at inference time since we
have to compute a lot of exponentials to compute the activation for
negative preactivations. <strong>If compute resources are not an issue
for you, or if the network is not gigantic, go for ELU, other wise, you
might want to stick to Leaky ReLUs.</strong> Both LReLU and ELU add
another hyperparameter to be tuned.</p>
<p>â€ƒ3.If you have a lot of computational budget, and a lot of time, you
can contrast the performance of the above activations with those of
PReLU and Randomized ReLUs. Randomized ReLU can be useful if your
function shows overfitting. With Parametric ReLU, you add a whole bunch
of parameters to be learned to your optimisation problem. Therefore,
Parameterized ReLU should be used only if you have a lot of training
data.</p>
<h1 id="conclusion">Conclusion</h1>
<p>In this post, we covered the need for a constant and well behaved
distribution of data being fed to layers of a neural network for it
learn properly. While activation functions implicitly try to normalize
these distributions, a technique called Batch Normalization does this
explicitly, and it wouldnâ€™t be wrong to say that it has been one of the
major breakthroughs in the field of deep learning in the recent years.
However, that will be covered in the next part of the series, till then,
you can try your hand at trying out different activations for your
network! Have fun experimenting!</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="å¤´åƒ"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/65b6b29c871b83018af70c9a.png" title="å¤´åƒ" alt="å¤´åƒ"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/65b6b29c871b83018af70c9a.png" title="å¤´åƒ" alt="å¤´åƒ"></a><div class="post-copyright__author_name">sparkle520</div><div class="post-copyright__author_desc">æˆ‘ä¸€ç›´éƒ½åœ¨å¯»æ‰¾ç€ä»€ä¹ˆ</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="è¯¥æ–‡ç« ä¸ºåŸåˆ›æ–‡ç« ï¼Œæ³¨æ„ç‰ˆæƒåè®®" href="http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/">åŸåˆ›</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/')">Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="ä½¿ç”¨æ‰‹æœºè®¿é—®è¿™ç¯‡æ–‡ç« "><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/"></div><div class="reward-dec">ä½¿ç”¨æ‰‹æœºè®¿é—®è¿™ç¯‡æ–‡ç« </div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Vanishing Gradients and Choosing the Right Activation Function - By Ayoosh Kathuria&amp;url=http://example.com/2024/10/29/VanishingGradientsAndChoosingtheRightActivationFunction/&amp;pic=https://pic.imgdb.cn/item/67179e86d29ded1a8c89ad6b.jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="å¤åˆ¶é“¾æ¥" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="http://example.com" target="_blank">SPARKLE</a>ï¼</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/python/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>python<span class="tagsPageCount">5</span></a><a class="post-meta__box__tags" href="/tags/Deep-Learning/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Deep Learning<span class="tagsPageCount">1</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://pic1.imgdb.cn/item/6996f0a1d2628f800ee0f993.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/27/Matplotlib_%E5%9B%BE%E7%AA%97%E5%B1%9E%E6%80%A7/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/671e4534d29ded1a8c489f22.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Matplotlib - å›¾çª—å±æ€§</div></div></a></div><div class="next-post pull-right"><a href="/2024/10/30/%E8%8B%B1%E8%AF%AD%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/67238da6d29ded1a8c76b439.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">å®šè¯­ä»å¥ä»å…¥é—¨åˆ°é«˜çº§ ( Attributive Clause )</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>å–œæ¬¢è¿™ç¯‡æ–‡ç« çš„äººä¹Ÿçœ‹äº†</span></div><div class="relatedPosts-list"><div><a href="/2024/10/27/Matplotlib_%E4%BA%8C%E7%BB%B4%E5%9B%BE/" title="Matplotlib - äºŒç»´å›¾"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/671ce86bd29ded1a8c4d79b5.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-10-27</div><div class="title">Matplotlib - äºŒç»´å›¾</div></div></a></div><div><a href="/2024/10/27/Matplotlib_%E7%BB%9F%E8%AE%A1%E5%9B%BE/" title="Matplotlib - ç»Ÿè®¡å›¾"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/671e08aed29ded1a8c1a609e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-10-27</div><div class="title">Matplotlib - ç»Ÿè®¡å›¾</div></div></a></div><div><a href="/2024/10/27/Matplotlib_%E5%9B%BE%E7%AA%97%E5%B1%9E%E6%80%A7/" title="Matplotlib - å›¾çª—å±æ€§"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/671e4534d29ded1a8c489f22.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-10-27</div><div class="title">Matplotlib - å›¾çª—å±æ€§</div></div></a></div><div><a href="/2024/11/28/python%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/" title="python åºåˆ—åŒ–å’Œååºåˆ—åŒ– ( Serialization &amp; deserialization )"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/67485e4ed0e0a243d4da5fd8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-11-28</div><div class="title">python åºåˆ—åŒ–å’Œååºåˆ—åŒ– ( Serialization &amp; deserialization )</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> è¯„è®º</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">åŒ¿åè¯„è®º</a><a href="/privacy" style="margin-left: 4px">éšç§æ”¿ç­–</a></div><div class="comment-tips" id="comment-tips"><span>âœ… ä½ æ— éœ€åˆ é™¤ç©ºè¡Œï¼Œç›´æ¥è¯„è®ºä»¥è·å–æœ€ä½³å±•ç¤ºæ•ˆæœ</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/65b6b29c871b83018af70c9a.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic.imgdb.cn/item/671cfe2fd29ded1a8c5ffb0b.png" alt="status"/></div></div><div class="author-info__description">ä¸ç®¡ä½ åœ¨<strong style="color:white">è¿™ä¸ªä¸–ç•Œ</strong>çš„å“ªä¸ªåœ°æ–¹ï¼Œæˆ‘ä¸€å®š<strong style="color:white">ä¼š</strong>ï¼Œå†æ¬¡å»<strong style="color:white">è§</strong>ä½ çš„!</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">sparkle520</h1><div class="author-info__desc">æˆ‘ä¸€ç›´éƒ½åœ¨å¯»æ‰¾ç€ä»€ä¹ˆ</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/sparkle520" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/34882250" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">Hello World! æ¬¢è¿æ¥åˆ°æˆ‘çš„åšå®¢~</div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://pic.imgdb.cn/item/66c487f1d9c307b7e9ba5c7a.png) center center / 100% no-repeat"></div><div class="back face" style="background: url(https://pic.imgdb.cn/item/66c487ebd9c307b7e9ba5725.png) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>æ–‡ç« ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#distributions-damned-distributions-and-statistics"><span class="toc-number">1.</span> <span class="toc-text">Distributions,
Damned Distributions and Statistics</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#vanishing-gradients"><span class="toc-number">2.</span> <span class="toc-text">Vanishing Gradients</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#saturated-neurons"><span class="toc-number">3.</span> <span class="toc-text">Saturated Neurons</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#relu-to-the-rescue"><span class="toc-number">4.</span> <span class="toc-text">ReLU to the rescue</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#one-sided-saturations"><span class="toc-number">5.</span> <span class="toc-text">One-sided Saturations</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#information-disentanglement-and-robustness-to-noise"><span class="toc-number">6.</span> <span class="toc-text">Information
Disentanglement and Robustness to Noise</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sparsity"><span class="toc-number">7.</span> <span class="toc-text">Sparsity</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#the-dying-relu-problem"><span class="toc-number">8.</span> <span class="toc-text">The Dying ReLU Problem</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#zero-centered-activations"><span class="toc-number">9.</span> <span class="toc-text">Zero-centered activations</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#leaky-relus-and-parameterized-relus"><span class="toc-number">10.</span> <span class="toc-text">Leaky ReLUs and
Parameterized ReLUs</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#revisting-saturation"><span class="toc-number">11.</span> <span class="toc-text">Revisting Saturation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#exponential-linear-units-and-bias-shift"><span class="toc-number">12.</span> <span class="toc-text">Exponential Linear
Units and Bias Shift</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#how-to-chose-a-activation-function"><span class="toc-number">13.</span> <span class="toc-text">How to chose a activation
function</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#conclusion"><span class="toc-number">14.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>æœ€è¿‘å‘å¸ƒ</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/19/%E9%AB%98%E6%95%B0-%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0%E6%B1%82%E8%A7%A3/" title="é«˜ç­‰æ•°å­¦-éš¾ç‚¹-é«˜é˜¶å¯¼æ•°æ±‚è§£"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6996f0a1d2628f800ee0f993.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="é«˜ç­‰æ•°å­¦-éš¾ç‚¹-é«˜é˜¶å¯¼æ•°æ±‚è§£"/></a><div class="content"><a class="title" href="/2026/02/19/%E9%AB%98%E6%95%B0-%E9%AB%98%E9%98%B6%E5%AF%BC%E6%95%B0%E6%B1%82%E8%A7%A3/" title="é«˜ç­‰æ•°å­¦-éš¾ç‚¹-é«˜é˜¶å¯¼æ•°æ±‚è§£">é«˜ç­‰æ•°å­¦-éš¾ç‚¹-é«˜é˜¶å¯¼æ•°æ±‚è§£</a><time datetime="2026-02-19T12:00:27.000Z" title="å‘è¡¨äº 2026-02-19 20:00:27">2026-02-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/%E8%AE%A1%E7%BB%845/" title="408-è®¡ç®—æœºç»„æˆåŸç†-5-ä¸­å¤®å¤„ç†å™¨"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/69872af342b1cbeca1f88f3d.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="408-è®¡ç®—æœºç»„æˆåŸç†-5-ä¸­å¤®å¤„ç†å™¨"/></a><div class="content"><a class="title" href="/2026/01/26/%E8%AE%A1%E7%BB%845/" title="408-è®¡ç®—æœºç»„æˆåŸç†-5-ä¸­å¤®å¤„ç†å™¨">408-è®¡ç®—æœºç»„æˆåŸç†-5-ä¸­å¤®å¤„ç†å™¨</a><time datetime="2026-01-26T15:00:27.000Z" title="å‘è¡¨äº 2026-01-26 23:00:27">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/26/%E8%AE%A1%E7%BB%844/" title="408-è®¡ç®—æœºç»„æˆåŸç†-4-æŒ‡ä»¤ç³»ç»Ÿ"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/69872ac742b1cbeca1f88f3a.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="408-è®¡ç®—æœºç»„æˆåŸç†-4-æŒ‡ä»¤ç³»ç»Ÿ"/></a><div class="content"><a class="title" href="/2026/01/26/%E8%AE%A1%E7%BB%844/" title="408-è®¡ç®—æœºç»„æˆåŸç†-4-æŒ‡ä»¤ç³»ç»Ÿ">408-è®¡ç®—æœºç»„æˆåŸç†-4-æŒ‡ä»¤ç³»ç»Ÿ</a><time datetime="2026-01-26T15:00:27.000Z" title="å‘è¡¨äº 2026-01-26 23:00:27">2026-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/14/%E8%AE%A1%E7%BB%843/" title="408-è®¡ç®—æœºç»„æˆåŸç†-3-å­˜å‚¨ç³»ç»Ÿ"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/69677a4999f37a647f58e412.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="408-è®¡ç®—æœºç»„æˆåŸç†-3-å­˜å‚¨ç³»ç»Ÿ"/></a><div class="content"><a class="title" href="/2026/01/14/%E8%AE%A1%E7%BB%843/" title="408-è®¡ç®—æœºç»„æˆåŸç†-3-å­˜å‚¨ç³»ç»Ÿ">408-è®¡ç®—æœºç»„æˆåŸç†-3-å­˜å‚¨ç³»ç»Ÿ</a><time datetime="2026-01-14T15:00:27.000Z" title="å‘è¡¨äº 2026-01-14 23:00:27">2026-01-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/12/%E8%8B%B1%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%AE%80%E5%8C%96/" title="è‹±è¯­ä»å¥ç®€åŒ–"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://pic1.imgdb.cn/item/6964b36351d5e4e5d5707e53.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="è‹±è¯­ä»å¥ç®€åŒ–"/></a><div class="content"><a class="title" href="/2026/01/12/%E8%8B%B1%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%AE%80%E5%8C%96/" title="è‹±è¯­ä»å¥ç®€åŒ–">è‹±è¯­ä»å¥ç®€åŒ–</a><time datetime="2026-01-12T15:00:27.000Z" title="å‘è¡¨äº 2026-01-12 23:00:27">2026-01-12</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"></div><div id="footer-type-tips"></div><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#footer-type-tips", {
      strings: ["åªè¦è®°ä½ä½ çš„åå­—&#44; ä¸ç®¡ä½ åœ¨ä¸–ç•Œçš„å“ªä¸ªåœ°æ–¹&#44; æˆ‘ä¸€å®š&#44; ä¼šå»è§ä½  !"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("footer-type-tips").innerHTML = 'åªè¦è®°ä½ä½ çš„åå­—&#44; ä¸ç®¡ä½ åœ¨ä¸–ç•Œçš„å“ªä¸ªåœ°æ–¹&#44; æˆ‘ä¸€å®š&#44; ä¼šå»è§ä½  !'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.cbd.int/typed.js@2.1.0/dist/typed.umd.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/sparkle520" title="sparkle">sparkle</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">æ–‡ç« </div><div class="length-num">82</div></a><a href="/tags/" title="tag"><div class="headline">æ ‡ç­¾</div><div class="length-num">47</div></a><a href="/categories/" title="category"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><span class="sidebar-menu-item-title">åŠŸèƒ½</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="æ˜¾ç¤ºæ¨¡å¼"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>æ˜¾ç¤ºæ¨¡å¼</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">ç½‘é¡µ</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://github.com/sparkle520?tab=repositories" title="github"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="github"/><span class="back-menu-item-text">github</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æ–‡ç« </span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> åˆ†ç±»</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> æ ‡ç­¾</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> å‹é“¾</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> å‹äººå¸</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> æˆ‘çš„</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> ç›¸å†Œé›†</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> å°ç©ºè°ƒ</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> å…³äº</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> é—²è¨€ç¢è¯­</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> éšä¾¿é€›é€›</span></a></li></ul></div></div><span class="sidebar-menu-item-title">æ ‡ç­¾</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/408/" style="font-size: 0.88rem;">408<sup>10</sup></a><a href="/tags/AOP/" style="font-size: 0.88rem;">AOP<sup>1</sup></a><a href="/tags/Deep-Learning/" style="font-size: 0.88rem;">Deep Learning<sup>1</sup></a><a href="/tags/IoC/" style="font-size: 0.88rem;">IoC<sup>1</sup></a><a href="/tags/JSR303/" style="font-size: 0.88rem;">JSR303<sup>1</sup></a><a href="/tags/Matplotlib/" style="font-size: 0.88rem;">Matplotlib<sup>3</sup></a><a href="/tags/c/" style="font-size: 0.88rem;">c#<sup>2</sup></a><a href="/tags/java/" style="font-size: 0.88rem;">java<sup>4</sup></a><a href="/tags/npc%E5%88%86%E6%9E%90%E6%B3%95/" style="font-size: 0.88rem;">npcåˆ†ææ³•<sup>1</sup></a><a href="/tags/python/" style="font-size: 0.88rem;">python<sup>5</sup></a><a href="/tags/%E4%BA%8B%E5%8A%A1/" style="font-size: 0.88rem;">äº‹åŠ¡<sup>1</sup></a><a href="/tags/%E4%BA%8C%E6%AC%A1%E5%9E%8B/" style="font-size: 0.88rem;">äºŒæ¬¡å‹<sup>1</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E3%80%82/" style="font-size: 0.88rem;">ä½ çš„åå­—ã€‚<sup>3</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E5%90%8C%E5%90%8D%E5%B0%8F%E8%AF%B4/" style="font-size: 0.88rem;">ä½ çš„åå­—åŒåå°è¯´<sup>1</sup></a><a href="/tags/%E4%BD%A0%E7%9A%84%E5%90%8D%E5%AD%97%E5%A4%96%E4%BC%A0%E5%B0%8F%E8%AF%B4/" style="font-size: 0.88rem;">ä½ çš„åå­—å¤–ä¼ å°è¯´<sup>1</sup></a><a href="/tags/%E5%80%92%E8%A3%85%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">å€’è£…ç»“æ„<sup>1</sup></a><a href="/tags/%E5%86%99%E4%BD%9C/" style="font-size: 0.88rem;">å†™ä½œ<sup>4</sup></a><a href="/tags/%E5%8C%85%E7%AE%A1%E7%90%86/" style="font-size: 0.88rem;">åŒ…ç®¡ç†<sup>1</sup></a><a href="/tags/%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F/" style="font-size: 0.88rem;">å·ç§¯å…¬å¼<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90/" style="font-size: 0.88rem;">å¤©æ°”ä¹‹å­<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%B0%94%E4%B9%8B%E5%AD%90%E5%90%8C%E5%90%8D%E5%B0%8F%E8%AF%B4/" style="font-size: 0.88rem;">å¤©æ°”ä¹‹å­åŒåå°è¯´<sup>1</sup></a><a href="/tags/%E5%AE%9A%E7%A7%AF%E5%88%86/" style="font-size: 0.88rem;">å®šç§¯åˆ†<sup>1</sup></a><a href="/tags/%E5%B0%8F%E8%AF%B4/" style="font-size: 0.88rem;">å°è¯´<sup>3</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">æ“ä½œç³»ç»Ÿ<sup>5</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/" style="font-size: 0.88rem;">æ•°æ®æ ¡éªŒ<sup>1</sup></a><a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" style="font-size: 0.88rem;">æ¦‚ç‡è®º<sup>1</sup></a><a href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/" style="font-size: 0.88rem;">æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡<sup>7</sup></a><a href="/tags/%E6%B1%87%E7%BC%96/" style="font-size: 0.88rem;">æ±‡ç¼–<sup>9</sup></a><a href="/tags/%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80/" style="font-size: 0.88rem;">æ³°å‹’å±•å¼€<sup>1</sup></a><a href="/tags/%E7%89%B9%E5%BE%81%E5%80%BC/" style="font-size: 0.88rem;">ç‰¹å¾å€¼<sup>1</sup></a><a href="/tags/%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/" style="font-size: 0.88rem;">ç‰¹å¾å‘é‡<sup>1</sup></a><a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" style="font-size: 0.88rem;">çº¿æ€§ä»£æ•°<sup>1</sup></a><a href="/tags/%E8%8B%B1%E8%AF%AD%E5%90%AC%E5%8A%9B/" style="font-size: 0.88rem;">è‹±è¯­å¬åŠ›<sup>1</sup></a><a href="/tags/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/" style="font-size: 0.88rem;">è‹±è¯­è¯­æ³•<sup>16</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" style="font-size: 0.88rem;">è®¡ç®—æœºç»„æˆåŸç†<sup>6</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 0.88rem;">è®¡ç®—æœºç½‘ç»œ<sup>1</sup></a><a href="/tags/%E8%AF%8D%E6%A0%B9%E8%AF%8D%E7%BC%80/" style="font-size: 0.88rem;">è¯æ ¹è¯ç¼€<sup>1</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E4%BB%A3%E6%95%B0/" style="font-size: 0.88rem;">é«˜ç­‰ä»£æ•°<sup>2</sup></a><a href="/tags/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/" style="font-size: 0.88rem;">é«˜ç­‰æ•°å­¦<sup>9</sup></a><a href="/tags/%E9%AB%98%E9%A2%91%E8%AF%8D%E7%BB%84/" style="font-size: 0.88rem;">é«˜é¢‘è¯ç»„<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="ç›´è¾¾è¯„è®º"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="å¼€å…³å¼¹å¹•"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶é€‰ä¸­æ–‡æœ¬</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>ç²˜è´´æ–‡æœ¬</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>å¼•ç”¨åˆ°è¯„è®º</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>æ–°çª—å£æ‰“å¼€</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>å¤åˆ¶é“¾æ¥åœ°å€</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>å¤åˆ¶æ­¤å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>ä¸‹è½½æ­¤å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>æ–°çª—å£æ‰“å¼€å›¾ç‰‡</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>ç«™å†…æœç´¢</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>ç™¾åº¦æœç´¢</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>æ’­æ”¾éŸ³ä¹</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>åˆ‡æ¢åˆ°ä¸Šä¸€é¦–</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>åˆ‡æ¢åˆ°ä¸‹ä¸€é¦–</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>æŸ¥çœ‹æ‰€æœ‰æ­Œæ›²</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶æ­Œå</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>éšä¾¿é€›é€›</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>åšå®¢åˆ†ç±»</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>æ–‡ç« æ ‡ç­¾</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>å¤åˆ¶åœ°å€</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">å…³é—­çƒ­è¯„</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">æ·±è‰²æ¨¡å¼</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>è½‰ç‚ºç¹é«”</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.cbd.int/mermaid@10.9.1/dist/mermaid.min.js').then(runMermaid)
  }

  anzhiyu.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://sparkle521.xyz',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://sparkle521.xyz',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"><script async src="/js/anzhiyu/comment_barrage.js"></script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[å›¾ç‰‡]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[é“¾æ¥]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[ä»£ç ]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://sparkle521.xyz',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "æ— æ³•è·å–è¯„è®ºï¼Œè¯·ç¡®è®¤ç›¸å…³é…ç½®æ˜¯å¦æ­£ç¡®"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += 'æ²¡æœ‰è¯„è®º'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><div><canvas id="snow" style="position:fixed;top:0;left:0;width:100%;height:100%;z-index:99999;pointer-events:none"></canvas></div><script>const notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));</script><script async type="text/javascript" src="https://cdn.jsdelivr.net/gh/Candinya/Kratos-Rebirth@latest/source/js/snow.min.js"></script><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">é€šçŸ¥</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">ä½ å¥½å‘€</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>